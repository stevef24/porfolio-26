---
title: Codex Multi-Agent Orchestrating
description: A practical playbook for running codex like a small engineering team — parallel execution, tight quality gates, and a repeatable loop that stays green.
author: Stav Fernandes
date: 2026-02-19
---

import { codexMultiAgentOrchestratingSteps } from "./codex-multi-agent-orchestrating.steps";

<BlogWithCanvas>

We have all been there. You hand an agent a project, walk away feeling productive, and come back to a confident green summary while real CI is quietly on fire.

The fix is not a better prompt. It is the same fix that works for human teams: distinct jobs, parallel independent work, and a gate before anything merges.

## Think kitchen brigade, not lone chef

One chef trying to prep, cook, plate, and serve every dish will burn something. A brigade — each person owning a station — moves faster and catches mistakes before they leave the pass.

Your codex session works the same way. An **orchestrator** owns the plan, an **explorer** scouts the repo, **implementers** each take one atomic task, a **ci_runner** validates deterministically, and a review layer (**reviewer** + **security_auditor**) catches what the others missed. A **qa_test_author** fills coverage gaps and a **release_manager** handles ship day. The loop: Plan → Implement → CI → Review → Repeat.

<CodexOrchestrationLoop />

Why it works: each role owns one job so prompts stay short and hallucinated side-quests starve. Independent tasks run in parallel instead of blocking a single serial chain. Review and security run on every batch — not stapled to the end.

<AgentCodeWalkthrough steps={codexMultiAgentOrchestratingSteps}>

<CanvasStep index={0}>

## 1) Enable multi-agent in config.toml

Everything starts in `~/.codex/config.toml` (or `.codex/config.toml` for repo-specific overrides). Set `multi_agent = true` under `[features]`, then register each role in `[agents]` with a description and a path to its TOML file.

The practical scaling tip: set `max_threads = 12`. Twelve threads give enough headroom for parallel batches without slamming into rate limits. If you see 429 errors, bring it down — you can always scale up once you trust the loop.

</CanvasStep>

<CanvasStep index={1}>

## 2) The orchestrator — your team lead in TOML

The orchestrator role file is where the loop lives. It declares `model`, `model_reasoning_effort`, `approval_policy`, `sandbox_mode`, and `developer_instructions`.

Instructions tell it to maintain `plan.md`, delegate independent tasks to implementers in parallel, run all three gates after each batch, and convert findings into new tasks. Two rules keep things clean: no scope creep (extras go in a Later section) and small diffs (every update ends with Done / Next / Risks).

The orchestrator runs `gpt-5.3-codex` with `xhigh` reasoning because planning mistakes are the most expensive kind. This is where `model_reasoning_effort` matters most — get it right per role and you save tokens without losing quality.

</CanvasStep>

<CanvasStep index={2}>

## 3) Workers: explorer and implementer

The explorer maps file paths, finds CI configs, and suggests next probes — but never implements. Keeping exploration separate prevents the classic failure mode where an agent starts "fixing" things it was only supposed to understand.

Implementers do the opposite: one scoped task from `plan.md`, minimal change set, run lint/typecheck/tests, iterate until green, stop. The structured report (what changed, commands run, result) gives the orchestrator the feedback it needs.

The explorer runs at `low` reasoning — it is just reading files, no complex analysis. The implementer gets `medium` since it needs to reason about code changes, but tasks are scoped enough that deep thinking is waste. Both use `gpt-5.3-codex-spark` for speed.

</CanvasStep>

<CanvasStep index={3}>

## 4) Quality gates: CI, review, security

Every batch hits three gates before anything merges. The **ci_runner** mirrors CI locally and outputs pass/fail with root cause analysis. The **reviewer** performs PR-grade review — must-fix issues with file/line refs and a ship-or-block verdict. The **security_auditor** hunts for secrets leakage, injection risks, auth mistakes, and SSRF.

These are hard stops, not suggestions. A batch that cannot pass all three gates is not done. The reviewer and security auditor both run at `xhigh` reasoning — this is where you want the model to think deeply, not cut corners. The CI runner stays at `low` since it is running deterministic commands and parsing output. All three share `approval_policy = "never"` and `sandbox_mode = "danger-full-access"`, so the review gate itself is the quality control.

</CanvasStep>

<CanvasStep index={4}>

## 5) Coverage and release roles

The **qa_test_author** fills gaps: adds tests for changed behavior, writes minimal repro steps for bugs, verifies fixes with commands plus expected output. The **release_manager** handles release notes, rollout steps, rollback plan, and a pre-deploy checklist.

You do not need all eight roles on day one. Start with orchestrator, implementer, ci_runner, and reviewer. Add the rest when you feel the gap.

</CanvasStep>

<CanvasStep index={5}>

## 6) Verify and choose your model tier

A quick `ls` and TOML parse confirm codex can read everything. Pro subscribers get `codex-spark` for fast roles (explorer, implementer, ci_runner), while Plus subscribers use `gpt-5.3-codex` across the board. Heavy roles stay on `gpt-5.3-codex`.

The first-run prompt should tell the orchestrator to execute one bounded batch, run all three gates, update `plan.md`, and avoid expanding scope.

</CanvasStep>

</AgentCodeWalkthrough>

## Reasoning effort — spend tokens where they matter

Not every role needs deep thinking. The rule: roles that **decide** (orchestrator, reviewer, security) get `xhigh`. Roles that **execute** (explorer, ci_runner) get `low`. Roles that **create** (implementer, qa, release) sit in the middle.

| Role | Reasoning | Why |
| --- | --- | --- |
| orchestrator | xhigh | Planning mistakes cascade through every batch |
| reviewer | xhigh | Subtle bugs need deep analysis to surface |
| security_auditor | xhigh | Injection vectors hide in boring code |
| qa_test_author | high | Edge-case thinking improves coverage |
| implementer | medium | Scoped tasks with clear acceptance criteria |
| release_manager | medium | Structured output, not analytical |
| explorer | low | Reading files, no complex reasoning |
| ci_runner | low | Deterministic commands, simple parsing |

<ReasoningComplexityChart />

The saving is real. An `xhigh` call uses roughly 3-4x the tokens of a `low` call on the same prompt. By keeping fast roles cheap, you can afford to run the expensive review roles on every batch without blowing through your budget.

## MCP strategy without context bloat

Attach tools to roles, not globally. UI roles get UI MCPs, docs roles get search MCPs, review roles stay lean. If every role sees every tool, you pay in context noise and slower routing.

## Improving over time

After each run, log what broke and what fixed it into an append-only `docs/agent-notes.md`. Promote a lesson into `AGENTS.md` only when it repeats and measurably helps. Keep `AGENTS.md` curated by checking changes against eval outcomes.

## Two starter packs

Pick your risk tolerance. **Pro** runs Spark on fast roles for higher concurrency. **Plus** uses `gpt-5.3-codex` everywhere for reliability.

| Role | Pro | Plus |
| --- | --- | --- |
| orchestrator | gpt-5.3-codex | gpt-5.3-codex |
| explorer | gpt-5.3-codex-spark | gpt-5.3-codex |
| implementer | gpt-5.3-codex-spark | gpt-5.3-codex |
| ci_runner | gpt-5.3-codex-spark | gpt-5.3-codex |
| reviewer | gpt-5.3-codex | gpt-5.3-codex |
| security_auditor | gpt-5.3-codex | gpt-5.3-codex |

## The takeaway

<Annotate>Parallel where it helps</Annotate>. <Annotate type="underline" color="var(--va-green)">Strict gates where it matters</Annotate>. A single plan to prevent drift. `max_threads = 12` as your starting ceiling. That gives you faster delivery without chaos — and <Annotate type="highlight" color="oklch(0.85 0.15 85 / 0.35)">a loop you can trust enough to run unattended</Annotate>.

</BlogWithCanvas>
